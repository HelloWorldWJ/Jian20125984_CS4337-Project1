{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cc9eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPARK_HOME=/home/aono/CS4337/lib/python3.8/site-packages/pyspark\n"
     ]
    }
   ],
   "source": [
    "# Set path variable for SPARK_HOME：\n",
    "%env SPARK_HOME = /home/aono/CS4337/lib/python3.8/site-packages/pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "821f456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/17 19:33:22 WARN Utils: Your hostname, aono-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.137.128 instead (on interface ens33)\n",
      "21/10/17 19:33:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/10/17 19:33:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personalRatingsRDD:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1, 1.0), (0, 780, 2.0), (0, 590, 3.0), (0, 1210, 4.0), (0, 648, 5.0), (0, 344, 1.0), (0, 165, 2.0), (0, 153, 3.0), (0, 597, 4.0), (0, 1580, 5.0), (0, 231, 1.0)]\n",
      "\n",
      "\n",
      "RatingsRDD:\n",
      "[(0, (1, 1193, 5.0)), (9, (1, 661, 3.0)), (8, (1, 914, 3.0)), (5, (1, 3408, 4.0)), (1, (1, 2355, 5.0)), (8, (1, 1197, 3.0)), (9, (1, 1287, 5.0)), (9, (1, 2804, 5.0)), (8, (1, 594, 4.0)), (8, (1, 919, 4.0)), (8, (1, 595, 5.0)), (2, (1, 938, 4.0)), (1, (1, 2398, 4.0)), (4, (1, 2918, 4.0)), (3, (1, 1035, 5.0)), (8, (1, 2791, 4.0)), (8, (1, 2687, 3.0)), (7, (1, 2018, 4.0)), (3, (1, 3105, 5.0)), (9, (1, 2797, 4.0))]\n",
      "\n",
      "\n",
      "moviesRDD:\n",
      "[(1, 'Toy Story (1995)'), (2, 'Jumanji (1995)'), (3, 'Grumpier Old Men (1995)'), (4, 'Waiting to Exhale (1995)'), (5, 'Father of the Bride Part II (1995)'), (6, 'Heat (1995)'), (7, 'Sabrina (1995)'), (8, 'Tom and Huck (1995)'), (9, 'Sudden Death (1995)'), (10, 'GoldenEye (1995)'), (11, 'American President, The (1995)'), (12, 'Dracula: Dead and Loving It (1995)'), (13, 'Balto (1995)'), (14, 'Nixon (1995)'), (15, 'Cutthroat Island (1995)'), (16, 'Casino (1995)'), (17, 'Sense and Sensibility (1995)'), (18, 'Four Rooms (1995)'), (19, 'Ace Ventura: When Nature Calls (1995)'), (20, 'Money Train (1995)')]\n",
      "\n",
      "\n",
      "+------+-------+------+\n",
      "|userID|movieID|rating|\n",
      "+------+-------+------+\n",
      "|     1|   1193|   5.0|\n",
      "|     1|    661|   3.0|\n",
      "|     1|    914|   3.0|\n",
      "|     1|   3408|   4.0|\n",
      "|     1|   2355|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userID|movieID|rating|\n",
      "+------+-------+------+\n",
      "|     0|      1|   1.0|\n",
      "|     0|    780|   2.0|\n",
      "|     0|    590|   3.0|\n",
      "|     0|   1210|   4.0|\n",
      "|     0|    648|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/17 19:33:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/10/17 19:33:46 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/10/17 19:33:47 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/10/17 19:33:47 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.856073281534929\n",
      "\n",
      "\n",
      "5 Movies recommended for you:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userID|     recommendations|\n",
      "+------+--------------------+\n",
      "|    26|[{2129, 5.062573}...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "from pyspark.ml.recommendation import ALS # ml\n",
    "from pyspark.sql import Row\n",
    "\n",
    "    # parse---\n",
    "\n",
    "def parseRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "\n",
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle .\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "    # load---\n",
    "    \n",
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print(\"File %s does not exist.\" % ratingsFile)\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print(\"No ratings provided.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings\n",
    "\n",
    "    # Compute RMSE (Root Mean Squared Error)---\n",
    "    \n",
    "def computeRmse(model, data, n):\n",
    "    \"\"\"\n",
    "    Compute RMSE (Root Mean Squared Error).\n",
    "    \"\"\"\n",
    "    predictions = model.predictAll(data.map(lambda x: (x[0], x[1])))\n",
    "    predictionsAndRatings = predictions.map(lambda x: ((x[0], x[1]), x[2])) \\\n",
    "      .join(data.map(lambda x: ((x[0], x[1]), x[2]))) \\\n",
    "      .values()\n",
    "    return sqrt(predictionsAndRatings.map(lambda x: (x[0] - x[1]) ** 2).reduce(add) / float(n))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # set up environment\n",
    "    spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Movie Recommendation Engine\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "   \n",
    "    sc = spark.sparkContext\n",
    "\n",
    "    # load personal ratings\n",
    "    myRatings = loadRatings(os.path.abspath('/home/aono/CS4337/Project1/personalRatings.txt')) #Original：'/home/ashish/personalRatings.txt'\n",
    "    myRatingsRDD = sc.parallelize(myRatings, 1)\n",
    "    # (personal comments)easy to see and know what personalRatingsRDD is\n",
    "    print(\"personalRatingsRDD:\") \n",
    "    print(myRatingsRDD.take(20))\n",
    "    print(\"\\n\")\n",
    "   \n",
    "    \n",
    "    # load ratings and movie titles\n",
    "\n",
    "    movieLensHomeDir = os.path.abspath('/home/aono/CS4337/Project1/movielens/medium') #Original: '/home/ashish/movieData'\n",
    "\n",
    "    # ratings is an RDD of (last digit of timestamp, (userId, movieId, rating))\n",
    "    ratings = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseRating)\n",
    "    # (personal comments)easy to see and know what RatingsRDD is\n",
    "    print(\"RatingsRDD:\") \n",
    "    print(ratings.take(20))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # movies is an RDD of (movieId, movieTitle)\n",
    "    movie = sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie)\n",
    "    # (personal comments)easy to see and know what moviesRDD is\n",
    "    print(\"moviesRDD:\") \n",
    "    print(movie.take(20))\n",
    "    print(\"\\n\")\n",
    "    movies = dict(movie.collect())\n",
    "    # Original code: movies = dict(sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie).collect())\n",
    "\n",
    "    \n",
    "    \n",
    "    ##########################################################################################################\n",
    "    # my code here\n",
    "    ##########################################################################################################\n",
    "    ############################### PART2--MACHINE LEARNING ##################################################\n",
    "    ##########################################################################################################\n",
    "    \n",
    "    \n",
    "    # (personal comments) \n",
    "    # create RDDs and DataFrames\n",
    "    # DataFrames is helpful to read and operate!\n",
    "    # --RatingsRDD and DataFrame--\n",
    "    r1 = lambda line: Row(userID = line[1][0], movieID = line[1][1], rating = line[1][2]) # This is 2-D. Be careful!\n",
    "    Ratings_df = ratings.map(r1).toDF()\n",
    "    Ratings_df.show(5)\n",
    "    # (personal comments) \n",
    "    # maxIter is the maximum number of iterations to run (defaults to 10).\n",
    "    # regParam specifies the regularization parameter in ALS (defaults to 1.0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # --personalRatingsRDD and DataFrame--\n",
    "    r2 = lambda line: Row(userID = line[0], movieID = line[1], rating = line[2])\n",
    "    personalRatings_df = myRatingsRDD.map(r2).toDF()\n",
    "    personalRatings_df.show(5)\n",
    "    \n",
    "    \n",
    "    # (personal comments) 80% is training sets, 20% is testing sets\n",
    "    (training, test) = Ratings_df.randomSplit([.8,.2], seed = 3500)\n",
    "    \n",
    "    \n",
    "    # (personal comments) add the personalRatings data (for training)!\n",
    "    training = training.union(personalRatings_df)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Build the recommendation model using ALS on the training data\n",
    "    # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    \n",
    "    # (personal comments) \n",
    "    # use ALS model (important!)\n",
    "    # I tried to keep adjusting maxIter and regParam, and the RMSE was about 0.89 when they were 10 and 0.01,\n",
    "    # respectively, and about 0.87 when they were 15 and 0.05, respectively.\n",
    "    # After many attempts, I used both 20 and 0.06 and the RMSE was about 0.85, \n",
    "    # so maybe there is still a possibility optimization.\n",
    "    als = ALS(maxIter = 20, regParam = 0.06, userCol=\"userID\", itemCol=\"movieID\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    # show the RMSE\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Generate top 10 movie recommendations for each user\n",
    "    userRecs = model.recommendForAllUsers(10)\n",
    "    # Generate top 10 user recommendations for each movie\n",
    "    movieRecs = model.recommendForAllItems(10)\n",
    "    \n",
    "    # Generate top 10 movie recommendations for a specified set of users\n",
    "    users = Ratings_df.select(als.getUserCol()).distinct().limit(3)\n",
    "    userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "    # Generate top 10 user recommendations for a specified set of movies\n",
    "    movies = Ratings_df.select(als.getItemCol()).distinct().limit(3)\n",
    "    movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "    \n",
    "    \n",
    "    # userRecs.show()\n",
    "    # movieRecs.show()\n",
    "    userSubsetRecs.show()\n",
    "    movieSubSetRecs.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # output the recommented result\n",
    "    print(\"5 Movies recommended for you:\")\n",
    "    users = Ratings_df.select(als.getUserCol()).distinct().limit(1)\n",
    "    userSubsetRecs = model.recommendForUserSubset(users, 5)\n",
    "    userSubsetRecs.show()\n",
    "    \n",
    "    \n",
    "    # print(userSubsetRecs[1][2])\n",
    "    \n",
    "    \n",
    "    spark.stop()\n",
    "    \n",
    "    \n",
    "    # clean up\n",
    "    sc.stop() #close\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
